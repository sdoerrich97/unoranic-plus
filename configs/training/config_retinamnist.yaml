# xAILAB Bamberg
# Chair of Explainable Machine Learning
# Otto-Friedrich University of Bamberg
#
# @description:
# Parameter and hyperparameter configurations of the used models.
# retinamnist Dataset
#
# @author: Sebastian Doerrich
# @email: sebastian.doerrich@uni-bamberg.de

# ######################################
# Parameter and hyperparameter configurations for training
# ######################################
training:
  # Parameters
  dataset: 'retinamnist'  # Which dataset to use.
  data_path: '../data/MedMNIST/retinamnist.npz'  # Where the dataset is stored
  output_path: '../checkpoints/reconstruction'  # Parent directory to where the trained model shall be stored.
  architecture: 'unoranic+'  # Which model to use for training
  resume_training: # Whether to resume the training from a given checkpoint.
    resume: False  # Whether to load the checkpoint or not.
    wandb_id: 'xxx'  # wandb ID of the run to resume.
  seed: 1333  # Seed for random operations for reproducibility.
  device: 'cuda:0'  # Which device to run the computations on.
  hp_optimization: False  # Whether hyperparameter optimization is active.

  # Hyperparameters
  starting_epoch: 0  # Which epoch to start from.
  epochs: 150  # How many epochs to train for.
  img_size: 28  # Height and width of the input
  in_channel: 3  # Channel dimension of the input
  patch_size: 4  # Size of image patches.
  latent_dim: 128  # Feature dimension of latent space.
  depth: 12  # Depth (Number of blocks) of the encoder and decoder.
  num_heads: 16  # Number of attention heads.
  mlp_ratio: 4.  # Ratio of the hidden dimension compared to the input dimension of the Multi-Layer-Perceptron (MLP) - layer.
  norm_layer: 'nn.LayerNorm'  # Normalization layer.
  batch_size: 64  # Batch size for the training.
  tuple_size: 4  # Size for Anatomy Tuple.
  dropout: 0.0  # Dropout rate.
  optimizer: # Optimizer
    learning_rate: 0.001  # Learning rate
    learning_rate_min: 0.  # Minimum learning rate
    first_momentum: 0.90  # First momentum for Adam
    second_momentum: 0.95  # Second momentum for Adam
    weight_decay: 0.05  # Weight decay
    warmup_epochs: 20  # Number of warmup epochs for the learning rate

# ######################################
# Parameter and hyperparameter configurations for inference
# ######################################
inference:
  # Parameters
  dataset: 'retinamnist'  # Which dataset to use.
  data_path: '../data/MedMNIST/retinamnist.npz'  # Where the dataset is stored
  input_path: '../checkpoints/reconstruction'  # Parent directory to where the trained encoder is stored.
  output_path: '../output/reconstruction'  # Parent directory to where the trained model shall be stored.
  architecture: 'unoranic+'  # Which model to use.
  seed: 1333  # Seed for random operations for reproducibility.
  device: 'cuda:0'  # Which device to run the computations on.

  # Hyperparameters
  img_size: 28  # Height and width of the input
  in_channel: 3  # Channel dimension of the input
  patch_size: 4  # Size of image patches.
  latent_dim: 128  # Feature dimension of latent space.
  depth: 12  # Depth (Number of blocks) of the encoder and decoder.
  num_heads: 16  # Number of attention heads.
  mlp_ratio: 4.  # Ratio of the hidden dimension compared to the input dimension of the Multi-Layer-Perceptron (MLP) - layer.
  norm_layer: 'nn.LayerNorm'  # Normalization layer.
  batch_size: 512  # Batch size for the training.
  tuple_size: 4  # Size for Anatomy Tuple.
  dropout: 0.0  # Dropout rate.
